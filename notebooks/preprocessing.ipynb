{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXWEAze4mmefUBtAoSJeTY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OGjB_MEGGgxB"},"outputs":[],"source":["# !pip install kagglehub"]},{"cell_type":"code","source":["# import kagglehub\n","# import shutil\n","\n","# # Download dataset\n","# path = kagglehub.dataset_download(\"sumn2u/garbage-classification-v2\")\n","# print(\"Path to dataset files:\", path)\n","\n","# # Mount Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# # Copy to your target folder in Drive\n","# target_path = \"/content/drive/MyDrive/RecycleVision/datas/\"\n","# shutil.copytree(path, target_path, dirs_exist_ok=True)\n","\n","# print(\"Dataset copied to:\", target_path)"],"metadata":{"id":"Q8MGvAk-GtbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wO3RpEwWDcjg","executionInfo":{"status":"ok","timestamp":1756625787708,"user_tz":-330,"elapsed":19271,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"fe6f2c98-74d0-4824-f0d2-7e3c7673c81f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Path where dataset was copied\n","dataset_path = \"/content/drive/MyDrive/RecycleVision/datas/garbage-dataset\"\n","\n","# List all class folders\n","classes = os.listdir(dataset_path)\n","print(\"Classes:\", classes)\n","print(\"Total classes:\", len(classes))\n","\n","# Count images in each class\n","for cls in classes:\n","    cls_path = os.path.join(dataset_path, cls)\n","    num_images = len(os.listdir(cls_path))\n","    print(f\"{cls}: {num_images} images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gjxi3tx4GyCX","executionInfo":{"status":"ok","timestamp":1756625809907,"user_tz":-330,"elapsed":22196,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"a4a961f6-69c3-4e7b-bc7f-49600cbac0c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'paper', 'plastic', 'trash', 'shoes', 'metal']\n","Total classes: 10\n","battery: 944 images\n","biological: 997 images\n","cardboard: 1825 images\n","clothes: 5327 images\n","glass: 3061 images\n","paper: 1680 images\n","plastic: 1984 images\n","trash: 947 images\n","shoes: 1977 images\n","metal: 1020 images\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, random_split\n","from torchvision import datasets, transforms\n","\n","data_dir = \"/content/drive/MyDrive/RecycleVision/datas/garbage-dataset\"\n","\n","classes = os.listdir(data_dir)\n","print('Classes: ', classes)\n","print('Total Classes: ', len(classes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-Y_0_qmRjtn","executionInfo":{"status":"ok","timestamp":1756625827369,"user_tz":-330,"elapsed":17460,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"f23bfb5e-76d8-40a5-f3bb-66dc3474ec13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Classes:  ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'paper', 'plastic', 'trash', 'shoes', 'metal']\n","Total Classes:  10\n"]}]},{"cell_type":"code","source":["train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(20),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean = [0.485,0.456,0.406],  #imagenet Mean\n","                         std = [0.229,0.224,0.225]) #imageNet std\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406],\n","                         std = [0.229,0.224,0.225])\n","])\n","\n","#loadingDataset\n","full_dataset = datasets.ImageFolder(data_dir,transform=train_transform)\n","\n","#traintestsplit\n","train_size = int(0.8 * len(full_dataset))\n","val_size = len(full_dataset) - train_size\n","train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n","\n","#for validation , override transform\n","val_dataset.dataset.transform = val_transform\n","\n","print(f\"Total images: {len(full_dataset)}\")\n","print(f\"Training: {len(train_dataset)}\")\n","print(f\"Validation: {len(val_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xjhFpPNT73w","executionInfo":{"status":"ok","timestamp":1756625827695,"user_tz":-330,"elapsed":328,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"d601deea-4fb0-4cd0-8df9-f17b36d22a76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total images: 19762\n","Training: 15809\n","Validation: 3953\n"]}]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","print(\"Train loader batches:\", len(train_loader))\n","print(\"Validation loader batches:\", len(val_loader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tfMwC27AgbTH","executionInfo":{"status":"ok","timestamp":1756625827714,"user_tz":-330,"elapsed":17,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"4e7f4a63-e486-44d5-be19-0fb1c9efb757"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train loader batches: 495\n","Validation loader batches: 124\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","class_counts = Counter([label for _, label in full_dataset.samples])    #full_dataset.samples is a list of (image_path, label) tuples.\n","\n","class_names = full_dataset.classes\n","for cls_idx, count in class_counts.items():\n","    print(f\"{class_names[cls_idx]}: {count} images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTbtrMbRqXSR","executionInfo":{"status":"ok","timestamp":1756625827727,"user_tz":-330,"elapsed":11,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"decc1b2e-3dee-4f8b-c941-8c112af70edc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["battery: 944 images\n","biological: 997 images\n","cardboard: 1825 images\n","clothes: 5327 images\n","glass: 3061 images\n","metal: 1020 images\n","paper: 1680 images\n","plastic: 1984 images\n","shoes: 1977 images\n","trash: 947 images\n"]}]},{"cell_type":"code","source":["from torch.utils.data import WeightedRandomSampler\n","import numpy as np\n","\n","class_counts = np.bincount([label for _, label in full_dataset.samples])    #counts how many times each label appear\n","class_weights = 1./class_counts #inverse freq\n","\n","#assign weight to each sample(image)\n","sample_weights = [class_weights[label] for _, label in full_dataset.samples]\n","\n","#sampler for training set\n","train_sampler = WeightedRandomSampler(\n","    weights=sample_weights[:len(train_dataset)],\n","    num_samples=len(train_dataset),\n","    replacement=True\n",")\n","\n","# Update DataLoaders with sampler\n","train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)\n","\n","print(\"Imbalance handled: using WeightedRandomSampler for training\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z4BY47-nzfMo","executionInfo":{"status":"ok","timestamp":1756625827740,"user_tz":-330,"elapsed":12,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"2051d9f1-4143-44de-a902-fe3b52cb1be4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Imbalance handled: using WeightedRandomSampler for training\n"]}]},{"cell_type":"code","source":["1.0/class_counts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCWXZZHLMtmp","executionInfo":{"status":"ok","timestamp":1756628187064,"user_tz":-330,"elapsed":6,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"a035274a-debc-4c4b-d773-55cd58320f71"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.00105932, 0.00100301, 0.00054795, 0.00018772, 0.00032669,\n","       0.00098039, 0.00059524, 0.00050403, 0.00050582, 0.00105597])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["labels = [label for _,label in full_dataset.samples]\n","classCounts = np.bincount(labels)\n","classWeights = 1.0/class_counts\n","\n","len(train_dataset)"],"metadata":{"id":"dTWBLeKs-kro","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756632748063,"user_tz":-330,"elapsed":17,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"5b7553d9-01fd-4218-b836-95ec95b52ae8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15809"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["sample_weights = [class_weights[label] for _, label in full_dataset.samples]\n","\n","len(sample_weights[:len(train_dataset)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwDLa_ipK5Iy","executionInfo":{"status":"ok","timestamp":1756632764715,"user_tz":-330,"elapsed":6,"user":{"displayName":"Abdullah Khatri","userId":"08294424654355059886"}},"outputId":"3affcc85-2436-4cd2-ca5c-e96b09e7e785"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15809"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[],"metadata":{"id":"BLFWW0Hpa7uE"},"execution_count":null,"outputs":[]}]}